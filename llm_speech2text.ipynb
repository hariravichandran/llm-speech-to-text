{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41e7d5e6-7e72-4ff8-b57a-53f704c5ec4d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T03:08:44.124251Z",
     "iopub.status.busy": "2024-11-25T03:08:44.123968Z",
     "iopub.status.idle": "2024-11-25T03:08:49.244534Z",
     "shell.execute_reply": "2024-11-25T03:08:49.243593Z",
     "shell.execute_reply.started": "2024-11-25T03:08:44.124228Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting speechbrain\n",
      "  Downloading speechbrain-1.0.2-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting hyperpyyaml (from speechbrain)\n",
      "  Downloading HyperPyYAML-1.2.2-py3-none-any.whl.metadata (7.6 kB)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from speechbrain) (1.3.2)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from speechbrain) (1.26.3)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from speechbrain) (23.2)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from speechbrain) (1.11.2)\n",
      "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from speechbrain) (0.1.99)\n",
      "Requirement already satisfied: torch>=1.9 in /usr/local/lib/python3.11/dist-packages (from speechbrain) (2.1.1+cu121)\n",
      "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (from speechbrain) (2.1.1+cu121)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from speechbrain) (4.66.1)\n",
      "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.11/dist-packages (from speechbrain) (0.20.3)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain) (4.9.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain) (2023.6.0)\n",
      "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->speechbrain) (2.1.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub->speechbrain) (2.31.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/lib/python3/dist-packages (from huggingface-hub->speechbrain) (5.4.1)\n",
      "Collecting ruamel.yaml>=0.17.28 (from hyperpyyaml->speechbrain)\n",
      "  Downloading ruamel.yaml-0.18.6-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting ruamel.yaml.clib>=0.2.7 (from ruamel.yaml>=0.17.28->hyperpyyaml->speechbrain)\n",
      "  Downloading ruamel.yaml.clib-0.2.12-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.9->speechbrain) (2.1.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->speechbrain) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->huggingface-hub->speechbrain) (3.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->speechbrain) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->huggingface-hub->speechbrain) (2020.6.20)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.11/dist-packages (from sympy->torch>=1.9->speechbrain) (1.3.0)\n",
      "Downloading speechbrain-1.0.2-py3-none-any.whl (824 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m824.8/824.8 kB\u001b[0m \u001b[31m27.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading HyperPyYAML-1.2.2-py3-none-any.whl (16 kB)\n",
      "Downloading ruamel.yaml-0.18.6-py3-none-any.whl (117 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.8/117.8 kB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading ruamel.yaml.clib-0.2.12-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (739 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m739.1/739.1 kB\u001b[0m \u001b[31m53.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: ruamel.yaml.clib, ruamel.yaml, hyperpyyaml, speechbrain\n",
      "Successfully installed hyperpyyaml-1.2.2 ruamel.yaml-0.18.6 ruamel.yaml.clib-0.2.12 speechbrain-1.0.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install speechbrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28c40f2a-d2f3-4a25-956d-05c3344ca6d6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T03:08:49.249153Z",
     "iopub.status.busy": "2024-11-25T03:08:49.248894Z",
     "iopub.status.idle": "2024-11-25T03:08:52.449451Z",
     "shell.execute_reply": "2024-11-25T03:08:52.448604Z",
     "shell.execute_reply.started": "2024-11-25T03:08:49.249124Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:speechbrain.utils.quirks:Applied quirks (see `speechbrain.utils.quirks`): [allow_tf32, disable_jit_profiling]\n",
      "INFO:speechbrain.utils.quirks:Excluded quirks specified by the `SB_DISABLE_QUIRKS` environment (comma-separated list): []\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "from speechbrain.inference import EncoderDecoderASR\n",
    "import urllib.request\n",
    "import os\n",
    "import requests\n",
    "import tarfile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d92fd53-5cd6-427b-b568-c07254b8c545",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T03:08:52.451190Z",
     "iopub.status.busy": "2024-11-25T03:08:52.450937Z",
     "iopub.status.idle": "2024-11-25T03:09:07.601132Z",
     "shell.execute_reply": "2024-11-25T03:09:07.600275Z",
     "shell.execute_reply.started": "2024-11-25T03:08:52.451166Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:speechbrain.utils.fetching:Fetch hyperparams.yaml: Fetching from HuggingFace Hub 'speechbrain/asr-crdnn-rnnlm-librispeech' if not cached\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cdf43cb5294401a9a6d60a437d14c3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "hyperparams.yaml:   0%|          | 0.00/4.83k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:speechbrain.utils.fetching:Fetch custom.py: Fetching from HuggingFace Hub 'speechbrain/asr-crdnn-rnnlm-librispeech' if not cached\n",
      "INFO:speechbrain.utils.fetching:Fetch normalizer.ckpt: Fetching from HuggingFace Hub 'speechbrain/asr-crdnn-rnnlm-librispeech' if not cached\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ae3ad28223d4283b1bb2e2d24cc0448",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "normalizer.ckpt:   0%|          | 0.00/1.41k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:speechbrain.utils.fetching:Fetch asr.ckpt: Fetching from HuggingFace Hub 'speechbrain/asr-crdnn-rnnlm-librispeech' if not cached\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb5f3148bf354377b4850133d989f4e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "asr.ckpt:   0%|          | 0.00/480M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:speechbrain.utils.fetching:Fetch lm.ckpt: Fetching from HuggingFace Hub 'speechbrain/asr-crdnn-rnnlm-librispeech' if not cached\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1554178361554e6e920f68fa9af34f92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "lm.ckpt:   0%|          | 0.00/212M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:speechbrain.utils.fetching:Fetch tokenizer.ckpt: Fetching from HuggingFace Hub 'speechbrain/asr-crdnn-rnnlm-librispeech' if not cached\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5de8b982a3cc4782b140f2531cbda987",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.ckpt:   0%|          | 0.00/253k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:speechbrain.utils.parameter_transfer:Loading pretrained files for: normalizer, asr, lm, tokenizer\n"
     ]
    }
   ],
   "source": [
    "# Load pre-trained LLM-based speech recognition model\n",
    "asr_model = EncoderDecoderASR.from_hparams(source=\"speechbrain/asr-crdnn-rnnlm-librispeech\", savedir=\"tmpdir\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4537753-45e2-4d40-949b-b71208a69ee2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T03:09:07.602699Z",
     "iopub.status.busy": "2024-11-25T03:09:07.602287Z",
     "iopub.status.idle": "2024-11-25T03:09:29.917516Z",
     "shell.execute_reply": "2024-11-25T03:09:29.916411Z",
     "shell.execute_reply.started": "2024-11-25T03:09:07.602673Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading LibriSpeech dataset...\n",
      "Download complete: librispeech_data/dev-clean.tar.gz\n",
      "Extracting the dataset...\n",
      "Dataset extracted to: librispeech_data\n"
     ]
    }
   ],
   "source": [
    "# Define the URL for LibriSpeech\n",
    "librispeech_url = \"https://www.openslr.org/resources/12/dev-clean.tar.gz\"\n",
    "output_dir = \"librispeech_data\"\n",
    "output_file = os.path.join(output_dir, \"dev-clean.tar.gz\")\n",
    "\n",
    "# Create the output directory if it doesn't exist\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Download the dataset\n",
    "print(\"Downloading LibriSpeech dataset...\")\n",
    "response = requests.get(librispeech_url, stream=True)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    with open(output_file, \"wb\") as f:\n",
    "        for chunk in response.iter_content(chunk_size=8192):\n",
    "            f.write(chunk)\n",
    "    print(f\"Download complete: {output_file}\")\n",
    "else:\n",
    "    print(f\"Failed to download LibriSpeech dataset. HTTP Status: {response.status_code}\")\n",
    "\n",
    "# Extract the tar.gz file\n",
    "print(\"Extracting the dataset...\")\n",
    "with tarfile.open(output_file, \"r:gz\") as tar:\n",
    "    tar.extractall(path=output_dir)\n",
    "print(f\"Dataset extracted to: {output_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1d8e90d-68e4-48f7-b630-fcbb529f99dd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T03:09:29.919892Z",
     "iopub.status.busy": "2024-11-25T03:09:29.919621Z",
     "iopub.status.idle": "2024-11-25T03:09:34.882610Z",
     "shell.execute_reply": "2024-11-25T03:09:34.881798Z",
     "shell.execute_reply.started": "2024-11-25T03:09:29.919869Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:speechbrain.utils.fetching:Fetch hyperparams.yaml: Fetching from HuggingFace Hub 'speechbrain/asr-crdnn-rnnlm-librispeech' if not cached\n",
      "INFO:speechbrain.utils.fetching:Fetch custom.py: Fetching from HuggingFace Hub 'speechbrain/asr-crdnn-rnnlm-librispeech' if not cached\n",
      "INFO:speechbrain.utils.fetching:Fetch normalizer.ckpt: Fetching from HuggingFace Hub 'speechbrain/asr-crdnn-rnnlm-librispeech' if not cached\n",
      "INFO:speechbrain.utils.fetching:Fetch asr.ckpt: Fetching from HuggingFace Hub 'speechbrain/asr-crdnn-rnnlm-librispeech' if not cached\n",
      "INFO:speechbrain.utils.fetching:Fetch lm.ckpt: Fetching from HuggingFace Hub 'speechbrain/asr-crdnn-rnnlm-librispeech' if not cached\n",
      "INFO:speechbrain.utils.fetching:Fetch tokenizer.ckpt: Fetching from HuggingFace Hub 'speechbrain/asr-crdnn-rnnlm-librispeech' if not cached\n",
      "INFO:speechbrain.utils.parameter_transfer:Loading pretrained files for: normalizer, asr, lm, tokenizer\n"
     ]
    }
   ],
   "source": [
    "asr_model = EncoderDecoderASR.from_hparams(source=\"speechbrain/asr-crdnn-rnnlm-librispeech\", savedir=\"tmpdir\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49868a31-791f-4517-aaae-eba71e4c0cb1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T03:09:34.885734Z",
     "iopub.status.busy": "2024-11-25T03:09:34.885499Z",
     "iopub.status.idle": "2024-11-25T03:09:50.011697Z",
     "shell.execute_reply": "2024-11-25T03:09:50.009652Z",
     "shell.execute_reply.started": "2024-11-25T03:09:34.885711Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:speechbrain.utils.fetching:Fetch hyperparams.yaml: Fetching from HuggingFace Hub 'speechbrain/asr-crdnn-rnnlm-librispeech' if not cached\n",
      "INFO:speechbrain.utils.fetching:Fetch custom.py: Fetching from HuggingFace Hub 'speechbrain/asr-crdnn-rnnlm-librispeech' if not cached\n",
      "INFO:speechbrain.utils.fetching:Fetch normalizer.ckpt: Fetching from HuggingFace Hub 'speechbrain/asr-crdnn-rnnlm-librispeech' if not cached\n",
      "INFO:speechbrain.utils.fetching:Fetch asr.ckpt: Fetching from HuggingFace Hub 'speechbrain/asr-crdnn-rnnlm-librispeech' if not cached\n",
      "INFO:speechbrain.utils.fetching:Fetch lm.ckpt: Fetching from HuggingFace Hub 'speechbrain/asr-crdnn-rnnlm-librispeech' if not cached\n",
      "INFO:speechbrain.utils.fetching:Fetch tokenizer.ckpt: Fetching from HuggingFace Hub 'speechbrain/asr-crdnn-rnnlm-librispeech' if not cached\n",
      "INFO:speechbrain.utils.parameter_transfer:Loading pretrained files for: normalizer, asr, lm, tokenizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waveform shape: torch.Size([1, 93680])\n",
      "wav_lens: tensor([1.])\n",
      "Transcription: (['MISTER QUILTER IS THE APOSTLE OF THE MIDDLE CLASSES AND WE ARE GLAD TO WELCOME HIS GOSPEL ⁇ '], [[224, 25, 3, 395, 53, 103, 55, 2, 5, 26, 27, 65, 44, 8, 2, 233, 10, 10, 44, 490, 1, 93, 1, 6, 71, 128, 777, 9, 71, 53, 23, 159, 11, 29, 203, 1, 26, 143, 0]])\n"
     ]
    }
   ],
   "source": [
    "# Path to the audio file\n",
    "audio_file = \"librispeech_data/LibriSpeech/dev-clean/1272/128104/1272-128104-0000.flac\"\n",
    "\n",
    "# Load the audio file\n",
    "waveform, sample_rate = torchaudio.load(audio_file)\n",
    "\n",
    "# Convert to mono if the waveform has more than one channel\n",
    "if waveform.shape[0] > 1:  # Check if there are multiple channels\n",
    "    waveform = torch.mean(waveform, dim=0, keepdim=True)\n",
    "\n",
    "# Resample the audio if required (ASR model typically expects 16kHz audio)\n",
    "target_sample_rate = 16000\n",
    "if sample_rate != target_sample_rate:\n",
    "    resampler = torchaudio.transforms.Resample(orig_freq=sample_rate, new_freq=target_sample_rate)\n",
    "    waveform = resampler(waveform)\n",
    "\n",
    "# Ensure waveform shape is (time,) by removing extra dimensions\n",
    "waveform = waveform.squeeze(0)\n",
    "\n",
    "# Initialize the ASR model\n",
    "asr_model = EncoderDecoderASR.from_hparams(source=\"speechbrain/asr-crdnn-rnnlm-librispeech\", savedir=\"tmpdir\")\n",
    "\n",
    "# Convert waveform to a batch tensor (batch size = 1)\n",
    "waveform = waveform.unsqueeze(0)  # Add batch dimension (1, time)\n",
    "wav_lens = torch.tensor([1.0])    # Full length for a single waveform\n",
    "\n",
    "# Debugging: Print shapes before feeding into the model\n",
    "print(f\"Waveform shape: {waveform.shape}\")  # Should be (1, time)\n",
    "print(f\"wav_lens: {wav_lens}\")\n",
    "\n",
    "# Perform speech recognition\n",
    "transcription = asr_model.transcribe_batch(waveform, wav_lens)\n",
    "\n",
    "# Print the transcription\n",
    "print(\"Transcription:\", transcription)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df6c6827-5ddf-4925-afa0-d08c905329e5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T03:09:50.018603Z",
     "iopub.status.busy": "2024-11-25T03:09:50.018362Z",
     "iopub.status.idle": "2024-11-25T03:14:44.145827Z",
     "shell.execute_reply": "2024-11-25T03:14:44.145261Z",
     "shell.execute_reply.started": "2024-11-25T03:09:50.018578Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:speechbrain.utils.fetching:Fetch hyperparams.yaml: Fetching from HuggingFace Hub 'speechbrain/asr-crdnn-rnnlm-librispeech' if not cached\n",
      "INFO:speechbrain.utils.fetching:Fetch custom.py: Fetching from HuggingFace Hub 'speechbrain/asr-crdnn-rnnlm-librispeech' if not cached\n",
      "INFO:speechbrain.utils.fetching:Fetch normalizer.ckpt: Fetching from HuggingFace Hub 'speechbrain/asr-crdnn-rnnlm-librispeech' if not cached\n",
      "INFO:speechbrain.utils.fetching:Fetch asr.ckpt: Fetching from HuggingFace Hub 'speechbrain/asr-crdnn-rnnlm-librispeech' if not cached\n",
      "INFO:speechbrain.utils.fetching:Fetch lm.ckpt: Fetching from HuggingFace Hub 'speechbrain/asr-crdnn-rnnlm-librispeech' if not cached\n",
      "INFO:speechbrain.utils.fetching:Fetch tokenizer.ckpt: Fetching from HuggingFace Hub 'speechbrain/asr-crdnn-rnnlm-librispeech' if not cached\n",
      "INFO:speechbrain.utils.parameter_transfer:Loading pretrained files for: normalizer, asr, lm, tokenizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: librispeech_data/LibriSpeech/dev-clean/1272/128104/1272-128104-0002.flac\n",
      "Transcription for 1272-128104-0002.flac: (['HE TELLS US THAT AT THIS FESTIVE SEASON OF THE YEAR WITH CHRISTMAS AND ROAST BEEF LOOMING BEFORE US SIMILES DRAWN FROM EATING AND ITS RESULTS OCCUR MOST READILY TO THE MIND ⁇ '], [[16, 359, 1, 160, 20, 58, 77, 47, 176, 245, 371, 1, 46, 8, 2, 363, 33, 907, 462, 1, 6, 165, 196, 7, 22, 11, 42, 194, 159, 12, 246, 160, 422, 28, 94, 95, 730, 15, 86, 125, 115, 12, 6, 346, 940, 1, 164, 23, 23, 98, 330, 468, 410, 9, 2, 440, 0]])\n",
      "\n",
      "Processing file: librispeech_data/LibriSpeech/dev-clean/1272/128104/1272-128104-0013.flac\n",
      "Transcription for 1272-128104-0013.flac: (['MISTER QUILTER HAS MISSED HIS CHANCE FOR HE HAS FAILED EVEN TO MAKE HIMSELF THE TOPPER OF PAINTING ⁇ '], [[224, 25, 3, 395, 53, 103, 193, 247, 4, 29, 789, 34, 16, 193, 827, 4, 242, 9, 300, 54, 130, 2, 9, 134, 25, 8, 127, 40, 7, 12, 0]])\n",
      "\n",
      "Processing file: librispeech_data/LibriSpeech/dev-clean/1272/128104/1272-128104-0001.flac\n",
      "Transcription for 1272-128104-0001.flac: ([\"NOR IS MISTER QUILTER'S MANNER LESS INTERESTING THAN HIS MATTER ⁇ \"], [[428, 55, 224, 25, 3, 395, 53, 103, 30, 1, 690, 590, 638, 12, 171, 29, 559, 0]])\n",
      "\n",
      "Processing file: librispeech_data/LibriSpeech/dev-clean/1272/128104/1272-128104-0007.flac\n",
      "Transcription for 1272-128104-0007.flac: (['PAINTING HE TELLS US IS OF A DIFFERENT QUALITY TO MATHEMATICS AND FINISH IN ART IS ADDING MORE EFFECT ⁇ '], [[127, 40, 7, 12, 16, 359, 1, 160, 55, 8, 5, 759, 716, 53, 161, 9, 147, 63, 11, 462, 404, 1, 6, 47, 40, 186, 13, 600, 55, 630, 12, 155, 825, 0]])\n",
      "\n",
      "Processing file: librispeech_data/LibriSpeech/dev-clean/1272/128104/1272-128104-0006.flac\n",
      "Transcription for 1272-128104-0006.flac: (['ON THE GENERAL PRINCIPLES OF ART AND MISTER QUILTER WRITES WITH EQUAL LUCIDITY ⁇ '], [[39, 2, 591, 72, 21, 40, 23, 452, 44, 1, 8, 600, 6, 224, 25, 3, 395, 53, 103, 660, 95, 33, 845, 451, 23, 124, 161, 0]])\n",
      "\n",
      "Processing file: librispeech_data/LibriSpeech/dev-clean/1272/128104/1272-128104-0000.flac\n",
      "Transcription for 1272-128104-0000.flac: (['MISTER QUILTER IS THE APOSTLE OF THE MIDDLE CLASSES AND WE ARE GLAD TO WELCOME HIS GOSPEL ⁇ '], [[224, 25, 3, 395, 53, 103, 55, 2, 5, 26, 27, 65, 44, 8, 2, 233, 10, 10, 44, 490, 1, 93, 1, 6, 71, 128, 777, 9, 71, 53, 23, 159, 11, 29, 203, 1, 26, 143, 0]])\n",
      "\n",
      "Processing file: librispeech_data/LibriSpeech/dev-clean/1272/128104/1272-128104-0009.flac\n",
      "Transcription for 1272-128104-0009.flac: (['HE LAMENTS MOST BITTERLY THE DIVORCE THAT HAS BEEN MADE BETWEEN DECORATIVE ART AND WHAT WE USUALLY CALL PICTURES MAKES A CUSTOMARY APPEAL TO THE LAST JUDGMENT AND REMINDS US THAT IN THE GREAT DAYS OF ART MICHAEL ANGELO WAS THE FURNISHING UPHOLSTERER ⁇ '], [[16, 152, 156, 1, 330, 75, 70, 103, 18, 2, 229, 97, 43, 69, 20, 193, 22, 32, 243, 521, 88, 23, 43, 707, 600, 6, 122, 71, 160, 382, 18, 339, 897, 1, 300, 1, 5, 64, 82, 7, 159, 398, 5, 134, 11, 61, 9, 2, 354, 445, 10, 45, 156, 6, 73, 28, 40, 10, 1, 160, 20, 13, 2, 212, 187, 1, 8, 600, 233, 101, 31, 143, 90, 154, 207, 19, 2, 47, 98, 15, 186, 12, 87, 60, 135, 1, 103, 25, 0]])\n",
      "\n",
      "Processing file: librispeech_data/LibriSpeech/dev-clean/1272/128104/1272-128104-0008.flac\n",
      "Transcription for 1272-128104-0008.flac: (['AS FOR ETCHINGS THEY ARE OF TWO KINDS BRITISH AND FOREIGN ⁇ '], [[38, 34, 125, 7, 101, 12, 1, 81, 128, 8, 222, 496, 1, 211, 70, 186, 6, 34, 11, 454, 0]])\n",
      "\n",
      "Processing file: librispeech_data/LibriSpeech/dev-clean/1272/128104/1272-128104-0010.flac\n",
      "Transcription for 1272-128104-0010.flac: (['NEAR THE FIRE AND THE ORNAMENTS FRED BROUGHT HOME FROM INDIA ON THE MENTAL BOARD ⁇ '], [[425, 2, 618, 6, 2, 104, 476, 156, 1, 47, 482, 596, 455, 86, 13, 10, 373, 39, 2, 3, 156, 61, 166, 200, 0]])\n",
      "\n",
      "Processing file: librispeech_data/LibriSpeech/dev-clean/1272/128104/1272-128104-0011.flac\n",
      "Transcription for 1272-128104-0011.flac: ([\"IN FACT HE FELT SEVERE ON MISTER RUSKIN FOR NOT RECOGNIZING THAT A PICTURE SHOULD DENOTE THE FRAILTY OF MAN AND REMARKS WITH PLEASING COURTESY AND FELICITY'S GRACE THAT MANY PHASES OF FEELING ⁇ \"], [[13, 589, 16, 495, 7, 3, 1, 316, 11, 39, 224, 25, 3, 21, 82, 68, 40, 34, 50, 442, 27, 45, 15, 435, 12, 20, 5, 897, 240, 88, 15, 27, 132, 2, 47, 102, 94, 249, 8, 137, 6, 818, 1, 33, 72, 44, 196, 12, 791, 95, 17, 6, 495, 114, 161, 30, 1, 264, 69, 20, 340, 72, 384, 93, 1, 8, 475, 12, 0]])\n",
      "\n",
      "Processing file: librispeech_data/LibriSpeech/dev-clean/1272/128104/1272-128104-0003.flac\n",
      "Transcription for 1272-128104-0003.flac: ([\"HE HAS GRIEVED DOUBTS WHETHER SIR FREDERICK LATIN'S WORK IS RUDDY GREEK AFTER ALL AND CAN DISCOVER IN IT BUT LITTLE OF ROCKY ITHACA ⁇ \"], [[16, 193, 107, 89, 11, 97, 4, 677, 1, 358, 477, 492, 47, 482, 11, 89, 118, 152, 7, 40, 30, 1, 364, 55, 3, 21, 36, 10, 10, 17, 107, 51, 11, 68, 210, 79, 6, 197, 824, 13, 24, 48, 178, 8, 165, 118, 17, 14, 63, 235, 31, 0]])\n",
      "\n",
      "Processing file: librispeech_data/LibriSpeech/dev-clean/1272/128104/1272-128104-0012.flac\n",
      "Transcription for 1272-128104-0012.flac: (['ONLY UNFORTUNATELY HIS OWN WORK NEVER DOES GET GOOD ⁇ '], [[39, 18, 146, 42, 43, 7, 199, 185, 18, 29, 291, 364, 269, 560, 319, 256, 0]])\n",
      "\n",
      "Processing file: librispeech_data/LibriSpeech/dev-clean/1272/128104/1272-128104-0005.flac\n",
      "Transcription for 1272-128104-0005.flac: (['IT IS OBVIOUSLY UNNECESSARY FOR US TO POINT OUT HOW LUMINOUS THESE CRITICISMS ARE HOW DELICATE IN EXPRESSION ⁇ '], [[24, 55, 164, 52, 97, 284, 18, 146, 116, 69, 1, 1, 398, 34, 160, 9, 551, 126, 195, 451, 28, 40, 206, 285, 418, 404, 142, 28, 1, 128, 195, 88, 113, 23, 185, 13, 3, 965, 0]])\n",
      "\n",
      "Processing file: librispeech_data/LibriSpeech/dev-clean/1272/128104/1272-128104-0014.flac\n",
      "Transcription for 1272-128104-0014.flac: (['BY HARRY QUILTER M A ⁇ '], [[74, 568, 131, 3, 395, 53, 103, 92, 5, 0]])\n",
      "\n",
      "Processing file: librispeech_data/LibriSpeech/dev-clean/1272/128104/1272-128104-0004.flac\n",
      "Transcription for 1272-128104-0004.flac: ([\"LINCOLN'S PICTURES ARE A SORT OF UPGUARDS AND ADAM PAINTINGS AND MASON'S EXQUISITE IDOLS ARE AS NATIONAL AS A JINGO POEM MISTER BURKETT FOSTER'S LANDSCAPES SMILE AT ONE MUCH IN THE SAME WAY THAT MISTER CARKER USED TO FLASH HIS TEETH AND MISTER JOHN CALLED HERE GIVES HIS SITTER A CHEERFUL SLAP ON THE BACK BEFORE HE SAYS LIKE A SHAMPOOER IN A TURKISH BATH NEXT MAN ⁇ \"], [[254, 15, 23, 135, 15, 30, 1, 897, 1, 128, 5, 751, 8, 87, 45, 36, 200, 1, 6, 5, 10, 189, 127, 40, 7, 12, 1, 6, 147, 1, 46, 30, 1, 138, 395, 1, 438, 14, 10, 135, 1, 128, 38, 3, 15, 111, 61, 38, 5, 3, 331, 12, 27, 223, 376, 224, 25, 75, 98, 184, 7, 7, 47, 27, 1, 103, 30, 1, 548, 1, 23, 31, 26, 95, 702, 58, 91, 92, 215, 13, 2, 390, 268, 20, 224, 25, 342, 68, 25, 160, 4, 9, 627, 1, 60, 29, 3, 132, 11, 63, 6, 224, 25, 620, 339, 4, 347, 318, 1, 29, 422, 7, 103, 5, 3, 293, 25, 188, 433, 31, 26, 39, 2, 274, 246, 16, 230, 1, 173, 5, 409, 28, 26, 27, 27, 25, 13, 5, 100, 98, 68, 186, 239, 63, 3, 586, 137, 0]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Path to the folder containing the audio files\n",
    "folder_path = \"librispeech_data/LibriSpeech/dev-clean/1272/128104\"\n",
    "\n",
    "# Initialize the ASR model\n",
    "asr_model = EncoderDecoderASR.from_hparams(source=\"speechbrain/asr-crdnn-rnnlm-librispeech\", savedir=\"tmpdir\")\n",
    "\n",
    "# Target sample rate for the ASR model\n",
    "target_sample_rate = 16000\n",
    "\n",
    "# Iterate through all FLAC files in the folder\n",
    "for file_name in os.listdir(folder_path):\n",
    "    if file_name.endswith(\".flac\"):  # Only process FLAC files\n",
    "        audio_file = os.path.join(folder_path, file_name)\n",
    "        print(f\"Processing file: {audio_file}\")\n",
    "\n",
    "        # Load the audio file\n",
    "        waveform, sample_rate = torchaudio.load(audio_file)\n",
    "\n",
    "        # Convert to mono if the waveform has more than one channel\n",
    "        if waveform.shape[0] > 1:  # Check if there are multiple channels\n",
    "            waveform = torch.mean(waveform, dim=0, keepdim=True)\n",
    "\n",
    "        # Resample the audio if required (ASR model typically expects 16kHz audio)\n",
    "        if sample_rate != target_sample_rate:\n",
    "            resampler = torchaudio.transforms.Resample(orig_freq=sample_rate, new_freq=target_sample_rate)\n",
    "            waveform = resampler(waveform)\n",
    "\n",
    "        # Ensure waveform shape is (time,) by removing extra dimensions\n",
    "        waveform = waveform.squeeze(0)\n",
    "\n",
    "        # Convert waveform to a batch tensor (batch size = 1)\n",
    "        waveform = waveform.unsqueeze(0)  # Add batch dimension (1, time)\n",
    "        wav_lens = torch.tensor([1.0])    # Full length for a single waveform\n",
    "\n",
    "        # Perform speech recognition\n",
    "        transcription = asr_model.transcribe_batch(waveform, wav_lens)\n",
    "\n",
    "        # Print the transcription\n",
    "        print(f\"Transcription for {file_name}: {transcription}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5575ee3-631f-4416-9ac9-d07c634d2779",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
